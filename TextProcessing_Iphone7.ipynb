{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##Twitter Sentiment Analysis for Iphone7 \n",
    "#Course - FA16-BL-ILS-Z639-35041\n",
    "#Author - Pawan Pinjarkar , Sunil Agrawal \n",
    "#Group - SMM Group 3 \n",
    "\n",
    "#Import Python libaries \n",
    "import pickle as pkl\n",
    "import re\n",
    "from __future__ import print_function\n",
    "from nltk.corpus import stopwords\n",
    "from datetime import timedelta\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "from operator import itemgetter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "##--------Input the datafile for text processing ------\n",
    "IphoneSentimentAnalysisFile = input(\"Please enter pickle file name with processed dataset for sentiment analysis =\")\n",
    "print (\"\\nThe entered dataset filename  is   =  \", IphoneSentimentAnalysisFile)\n",
    "print(\"Reading and processing the dataset .............................................\")\n",
    "#Build a dictionary whiich you want NLTK to ignore while removing stopwords. For example : not\n",
    "operators = set(('no', 'nor','not','shouldn','against','aren','couldn',\n",
    "                 'didn','doesn','hadn','hasn','haven','isn','mightn',\n",
    "                 'mustn','needn','shouldn','wasn','weren','won','wouldn'))\n",
    "stop = set(stopwords.words('english')) - operators\n",
    "# The list notWithPositiveNegativeList is created to handle scenarios where a tweet says \"I am not happy...\" , \n",
    "#\"I don't like...\". As \"happy\" is a positive word but when it is preceeded with \"not\", it implies nagative sentiment.\n",
    "notWithPositiveNegativeList = ['no','not','never',\"don't\"]\n",
    "fileList = []\n",
    "tweetAfterStopwords = []\n",
    "finalTweetDataList=[]\n",
    "finalTweetData = {}\n",
    "#The sentiments are classified as 'Positve' or 'Negative' based on NLTK lexicon dictionary\n",
    "pos_sent = open(\"positive-words.txt\").read()\n",
    "positive_words=pos_sent.split('\\n')\n",
    "neg_sent = open(\"negative-words.txt\",encoding='utf-8', errors='ignore').read()\n",
    "negative_words=neg_sent.split('\\n')\n",
    "sum =0\n",
    "data = pkl.load(open(IphoneSentimentAnalysisFile,\"rb\"))\n",
    "filelength = len(data)\n",
    "for j in range(filelength):\n",
    "    positive_counter = 0 \n",
    "    negative_counter = 0\n",
    "    sentiment = \"Undefined\"\n",
    "    tweetData = data[j]    \n",
    "    rawTweet = tweetData['ttext']\n",
    "    #This regular expression removes hashtags(#),mentions, urls but keeps single quote -- @[A-Za-z0-9]+)|([^0-9A-Za-z' \\t])|(\\w+:\\/\\/\\S+\n",
    "    #(For example, don't, haven't)\n",
    "    tweetCleanup = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z' \\t])|(\\w+:\\/\\/\\S+)\",\" \",rawTweet).split()).lower()    \n",
    "    stemmedWords = tweetCleanup.split(\" \")\n",
    "    wordCounter=0\n",
    "    # The sentiments are classifed as 'Positive' or 'Negative' based on below logic -\n",
    "    #If ‘number of +ve words’ >= ‘number of –ve words’ , classified as positive twee\n",
    "    #If ‘number of -ve words’ > ‘number of +ve words’ , classified as negative tweet\n",
    "    #If ‘number of +ve an d-ve words’ = 0 , classified as neutral tweet\n",
    "    for eachword in stemmedWords:\n",
    "        if eachword not in stop:\n",
    "            if eachword in positive_words:\n",
    "                if wordCounter is not 0 and stemmedWords[wordCounter-1]in notWithPositiveNegativeList:\n",
    "                    negative_counter = negative_counter+1\n",
    "                    wordCounter+=1\n",
    "                    continue\n",
    "                else:\n",
    "                    positive_counter = positive_counter+1\n",
    "            elif eachword in negative_words:\n",
    "                negative_counter = negative_counter+1\n",
    "        wordCounter+=1\n",
    "    if positive_counter > negative_counter:\n",
    "        sentiment =\"Positive\"\n",
    "    elif positive_counter < negative_counter:\n",
    "        sentiment =\"Negative\"        \n",
    "    elif positive_counter == negative_counter and positive_counter is not 0 and negative_counter is not 0:\n",
    "        # We have added a custom classifier 'ToDo' as currently we are not \n",
    "        # categorizing a sentiment based on intensity of words choosen in a tweet. \n",
    "        # We consider this is a future wotk. \n",
    "        sentiment = \"ToDo\" \n",
    "    else:\n",
    "        sentiment =\"Neutral\"\n",
    "    finalTweetData['tsentiment'] = sentiment\n",
    "    finalTweetData['tusername'] = tweetData['tusername']\n",
    "    finalTweetData['thandlename'] = tweetData['thandlename']\n",
    "    finalTweetData['tgender'] = tweetData['tgender']\n",
    "    finalTweetData['tlocation'] = tweetData['tlocation']\n",
    "    finalTweetData['tdate'] = tweetData['tdate']\n",
    "    finalTweetData['ttext'] = tweetData['ttext']\n",
    "    finalTweetDataList.append(finalTweetData.copy())\n",
    "    \n",
    "#Total Sentiments for given dataset\n",
    "PostiveCount=NegativeCount=NeutralCount=ToDoCount=0\n",
    "for i in range (len(finalTweetDataList)):\n",
    "    if finalTweetDataList[i]['tsentiment']==\"Positive\":\n",
    "        PostiveCount +=1\n",
    "    elif finalTweetDataList[i]['tsentiment']==\"Negative\":\n",
    "        NegativeCount +=1\n",
    "    elif finalTweetDataList[i]['tsentiment']==\"Neutral\":\n",
    "        NeutralCount +=1\n",
    "    elif finalTweetDataList[i]['tsentiment']==\"ToDo\":\n",
    "        ToDoCount +=1\n",
    "FinalClassifiedSentimentCount= len(finalTweetDataList)-ToDoCount     \n",
    "\n",
    "print(\"\\nTotal number of Sentimentts = \" , len(finalTweetDataList), \n",
    "\"\\nTotal number of Positive Sentiments =\" ,PostiveCount ,\n",
    "\"\\nTotal number of Negative Sentiments = \",NegativeCount ,\n",
    "\"\\nTotal number of Neutral Sentiments = \",NeutralCount, \n",
    "\"\\nTotal number of ToDo Sentiments(Noise) which is ignored = \",ToDoCount)\n",
    "print(\".....................................................................................\")        \n",
    "#Saving final PickleFile and CSV file \n",
    "pklfile=\"final\"+IphoneSentimentAnalysisFile\n",
    "pkl.dump(finalTweetDataList,open(pklfile,\"wb\"))\n",
    "print(\"\\nSaving the pickle file  : \",pklfile)\n",
    "keys = finalTweetDataList[0].keys()\n",
    "csvFile = 'final'+IphoneSentimentAnalysisFile+'.csv'\n",
    "with open(csvFile, 'w',encoding='UTF-8') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(finalTweetDataList)\n",
    "print(\"Saving the csv file : \",csvFile)\n",
    "finalTweetDataList = sorted(finalTweetDataList, key=itemgetter('tlocation'))\n",
    "sentimentsByStatesList=[]\n",
    "sentimentsByStatesDict={}\n",
    "for key, value in itertools.groupby(finalTweetDataList, key=itemgetter('tlocation')):\n",
    "    count=0\n",
    "    pCount=0\n",
    "    nCount=0\n",
    "    neutralCount=0\n",
    "    gender= \"\"\n",
    "    pMaleCount=0\n",
    "    pFemaleCount=0\n",
    "    nMaleCount=0\n",
    "    nFemaleCount=0\n",
    "    nuMaleCount=0\n",
    "    nuFemaleCount=0\n",
    "    for i in value:\n",
    "        sentiment=i.get('tsentiment')\n",
    "        if sentiment !='ToDo':\n",
    "            gender = i.get('tgender')\n",
    "            count +=1\n",
    "            if sentiment=='Positive':\n",
    "                pCount +=1\n",
    "                if gender=='Male':\n",
    "                    pMaleCount+=1\n",
    "                elif gender=='Female':\n",
    "                    pFemaleCount+=1\n",
    "            elif sentiment=='Negative':\n",
    "                nCount +=1\n",
    "                if gender=='Male':\n",
    "                    nMaleCount+=1\n",
    "                elif gender=='Female':\n",
    "                    nFemaleCount+=1\n",
    "            elif sentiment=='Neutral':\n",
    "                neutralCount +=1\n",
    "                if gender=='Male':\n",
    "                    nuMaleCount+=1\n",
    "                elif gender=='Female':\n",
    "                    nuFemaleCount+=1\n",
    "    sentimentsByStatesDict['State']=key\n",
    "    sentimentsByStatesDict['Total Sentiments']=count\n",
    "    sentimentsByStatesDict['Total number of positive sentiments']=pCount\n",
    "    sentimentsByStatesDict['Number of males with positive sentiments']=pMaleCount\n",
    "    sentimentsByStatesDict['Number of females with positive sentiments']=pFemaleCount\n",
    "    sentimentsByStatesDict['Total number of negative sentiments']=nCount\n",
    "    sentimentsByStatesDict['Number of males with negative sentiments']=nMaleCount\n",
    "    sentimentsByStatesDict['Number of females with negative sentiments']=nFemaleCount\n",
    "    sentimentsByStatesDict['Total number of neutral sentiments']=neutralCount\n",
    "    sentimentsByStatesDict['Number of males with neutral sentiments']=nuMaleCount\n",
    "    sentimentsByStatesDict['Number of females with neutral sentiments']=nuFemaleCount\n",
    "    \n",
    "    sentimentsByStatesList.append(sentimentsByStatesDict.copy())\n",
    "\n",
    "sentimentsByStatesList = sorted(sentimentsByStatesList, key=itemgetter('Total Sentiments'),reverse=True)\n",
    "columnSequence =['State','Total Sentiments','Total number of positive sentiments','Number of males with positive sentiments','Number of females with positive sentiments','Total number of negative sentiments','Number of males with negative sentiments','Number of females with negative sentiments','Total number of neutral sentiments','Number of males with neutral sentiments','Number of females with neutral sentiments']\n",
    "print(\".....................................................................................\")\n",
    "print(\"\\nFinal Number of Tweets Considered for Sentiment Analsyis(Exclused ToDo(Noise) classified Tweets) =\",FinalClassifiedSentimentCount,\n",
    "      \"\\n\\nGender and location based sentiments(Positive, Negative, and Neutral) for input file \",IphoneSentimentAnalysisFile)\n",
    "print(\".....................................................................................\")\n",
    "pd.DataFrame(sentimentsByStatesList).reindex(columns=columnSequence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
